import sys
import os
from pathlib import Path

# Add the backend directory to Python path
backend_dir = Path(__file__).parent.parent
sys.path.insert(0, str(backend_dir))

from mcp.server.fastmcp import FastMCP

from typing import List, Dict, Any
from setting import Settings


# 1Ô∏è‚É£ T·∫°o server
server = FastMCP("demo-mcp")

# Load settings
settings = Settings.load_settings()


# üöÄ Preload models ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô response
print("üöÄ Initializing models...")
from tool.model_manager import model_manager
model_manager.preload_models()
print("‚úÖ Models preloaded successfully!")

# 2Ô∏è‚É£ ƒê·ªãnh nghƒ©a tool
@server.tool()
def hello(name: str) -> str:
    """Say hello to a user"""
    return f"Hello, {name}!"


@server.tool()
def intent_classification(query: str) -> str:
    """
    Ph√¢n lo·∫°i intent c·ªßa c√¢u h·ªèi (s·ª≠ d·ª•ng cached models)
    Args:
        query: c√¢u h·ªèi c·ªßa user
    Returns:
        str: intent ƒë√£ ph√¢n lo·∫°i (vd: "recruitment", "salary", "company_info", ...)
    """
    from tool.model_manager import model_manager
    
    try:
        # L·∫•y semantic router t·ª´ cache
        semantic_router = model_manager.get_semantic_router()
        
        # Ph√¢n lo·∫°i intent
        print(f"\nüîç Classifying query: {query}")
        score, route_name = semantic_router.guide(query)
        print(f"‚úÖ Classification result: {route_name} (score: {score:.4f})")
        
        return route_name
        
    except Exception as e:
        print(f"‚ùå Error in intent classification: {str(e)}")
        return "unknown"

@server.tool()
def get_reflection(history: List[Dict[str, str]]) -> str:
    """
    S·ª≠ d·ª•ng Reflection ƒë·ªÉ t·ª± ƒë√°nh gi√° v√† c·∫£i thi·ªán c√¢u tr·∫£ l·ªùi
    Args:
        history: l·ªãch s·ª≠ h·ªôi tho·∫°i
        question: c√¢u h·ªèi hi·ªán t·∫°i
        max_iterations: s·ªë l·∫ßn l·∫∑p t·ªëi ƒëa ƒë·ªÉ c·∫£i thi·ªán c√¢u tr·∫£ l·ªùi
    Returns:
        str: c√¢u tr·∫£ l·ªùi ƒë√£ ƒë∆∞·ª£c c·∫£i thi·ªán
    """
    from tool.reflection import Reflection
    from llms.llm_manager import llm_manager
    
    # S·ª≠ d·ª•ng LLM Manager thay v√¨ t·∫°o instance m·ªõi
    default_url = "http://host.docker.internal:11434" if os.getenv("DOCKER_ENV") == "true" else "http://localhost:11434"
    ollama_url = os.getenv("OLLAMA_URL", settings.OLLAMA_BASE_URL or default_url)
    ollama_model = settings.OLLAMA_MODEL
    
    # Reuse existing LLM instance t·ª´ manager
    llm = llm_manager.get_ollama_client(base_url=ollama_url, model_name=ollama_model)
    reflection = Reflection(llm=llm)
    
    try:
        improved_answer = reflection.__call__(history)
        if "<think>" in improved_answer:
                improved_answer = improved_answer.split("</think>")[-1].strip()
        print("Reflection completed.", {"improved_answer": improved_answer})
        return improved_answer
    except Exception as e:
        print(f"‚ùå Error in reflection process: {str(e)}")
        return "Error in reflection process."
    
@server.tool()
def retrive_infor_company(query: str) -> List[Dict[str, Any]]:
    """
    Truy xu·∫•t th√¥ng tin c√¥ng ty t·ª´ Qdrant d·ª±a tr√™n c√¢u h·ªèi c·ªßa user
    Args:
        query: c√¢u h·ªèi c·ªßa user
    Returns:
        List[Dict]: danh s√°ch c√¥ng ty li√™n quan
    from tool.model_manager import model_manager
    """
    from tool.model_manager import model_manager
    
    try:
        # L·∫•y embedding model t·ª´ cache
        embedding_model = model_manager.get_embedding_model()
        
        # L·∫•y Qdrant client
        from tool.database import QDrant
        qdrant_client = QDrant(Settings=settings)
        
        # T·∫°o vector t·ª´ c√¢u h·ªèi
        query_vector = embedding_model.encode(query)
        
        # T√¨m ki·∫øm trong Qdrant
        results = qdrant_client.search_vectors(
            collection_name="companies",
            query_vector=query_vector,
            top_k=5
        )
        
        # Tr√≠ch xu·∫•t th√¥ng tin c√¥ng ty t·ª´ k·∫øt qu·∫£
        companies = []
        for res in results:
            payload = res.payload
            if payload:
                companies.append(payload)
        
        print(f"‚úÖ Retrieved {len(companies)} companies related to the query.")
        return companies
        
    except Exception as e:
        print(f"‚ùå Error retrieving company info: {str(e)}")
        return []



# 3Ô∏è‚É£ Ch·∫°y server qua STDIO
if __name__ == "__main__":
    server.run()
