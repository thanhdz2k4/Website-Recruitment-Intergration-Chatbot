class Reflection():
    def __init__(self, llm):
        self.llm = llm
    
    def _concat_and_format_texts(self, data):
        concatenatedTexts = []
        for entry in data:
            role = entry.get('role', '')
            if entry.get('parts'):
                all_texts = ' '.join(part['text'] for part in entry['parts'] )
            elif entry.get('content'):
                all_texts = entry['content'] 
            concatenatedTexts.append(f"{role}: {all_texts} \n")
        return ''.join(concatenatedTexts)
    
    
    def __call__(self, chatHistory, lastItemsConsidereds=100):
        
        if len(chatHistory) >= lastItemsConsidereds:
            chatHistory = chatHistory[len(chatHistory) - lastItemsConsidereds:]

        historyString = self._concat_and_format_texts(chatHistory)

        # L·∫•y c√¢u h·ªèi cu·ªëi c√πng c·ªßa user
        last_user_msg = ""
        for msg in reversed(chatHistory):
            if msg.get("role") == "user":
                last_user_msg = msg.get("content") or ""
                break

        prompt_template = """
B·∫°n nh·∫≠n ƒë∆∞·ª£c to√†n b·ªô l·ªãch s·ª≠ h·ªôi tho·∫°i gi·ªØa ng∆∞·ªùi d√πng (user) v√† tr·ª£ l√Ω (assistant).  

üéØ Nhi·ªám v·ª•:
- Vi·∫øt l·∫°i Y√äU C·∫¶U ho·∫∑c C√ÇU H·ªéI cu·ªëi c√πng c·ªßa NG∆Ø·ªúI D√ôNG th√†nh M·ªòT C√ÇU HO√ÄN CH·ªàNH v√† ƒê·ªòC L·∫¨P b·∫±ng ti·∫øng Vi·ªát.  
- Ph·∫£i K·∫æT H·ª¢P c√°c th√¥ng tin t·ª´ l·ªãch s·ª≠ ƒë·ªÉ c√¢u h·ªèi/ƒë·ªÅ ngh·ªã c√≥ th·ªÉ hi·ªÉu ƒë∆∞·ª£c m√† KH√îNG c·∫ßn xem l·∫°i l·ªãch s·ª≠.  
- C√¢u vi·∫øt ph·∫£i NG·∫ÆN G·ªåN, T·ª∞ NHI√äN v√† GI·ªÆ NGUY√äN √ù ƒê·ªäNH c·ªßa ng∆∞·ªùi d√πng.

üí° V√≠ d·ª•:
L·ªãch s·ª≠ h·ªôi tho·∫°i:
- User: "T√¨m vi·ªác ·ªü ƒë√¢y"
- Assistant: "B·∫°n mu·ªën t√¨m vi·ªác g√¨?"
- User: "H√† N·ªôi"

‚û°Ô∏è K·∫øt qu·∫£ mong ƒë·ª£i: "T√¥i mu·ªën t√¨m c√¥ng vi·ªác ·ªü H√† N·ªôi"
*** L∆∞u √Ω: V√≠ d·ª• ch·ªâ mang t√≠nh minh h·ªça
{historyString}
""".strip()


        filled_prompt = prompt_template.format(historyString=historyString, last_user_msg=last_user_msg)

        higherLevelSummariesPrompt = {
            "role": "user",
            "content": filled_prompt
        }

        print({"reflection_prompt": filled_prompt})

        completion = self.llm.generate_content([higherLevelSummariesPrompt])

        # Clean possible thinking tags or quotes
        if "</think>" in completion:
            completion = completion.split("</think>")[-1].strip()
        completion = completion.strip().strip('"')
        return completion

